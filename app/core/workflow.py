import logging
from typing import Dict, Any, List
from app.core.llm import llm_service
from app.core.rag import rag_service
from app.core.engine import ELE_Service

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class AgentState:
    def __init__(self, query: str, history: List[Dict]):
        self.query = query
        self.history = history  #  å­˜å‚¨å†å²
        self.final_answer = ""


class MeLA_Workflow:
    def __init__(self):
        logger.info("Initializing Agent Workflow...")

    def router_node(self, state: AgentState) -> str:
        # è·¯ç”±æ—¶ä¹Ÿå¯ä»¥å¸¦ä¸Š historyï¼Œä½†ä¸ºäº†çœ tokenï¼Œé€šå¸¸åªçœ‹æœ€æ–° query
        # æˆ–è€…ç®€åŒ–ä¸ºåªçœ‹ query
        intent = llm_service.chat(
            prompt=f"ç”¨æˆ·è¾“å…¥: '{state.query}'\nè¯·åˆ¤æ–­æ„å›¾ï¼šå¦‚æœæ¶‰åŠå†™ä»£ç /æ•°å­¦/ä¼˜åŒ–/TSPï¼Œè¿”å›'OPTIMIZE'ã€‚å¦‚æœæ˜¯é—²èŠ/æ¦‚å¿µè§£é‡Šï¼Œè¿”å›'CHAT'ã€‚åªè¿”å›å•è¯ã€‚",
            system_prompt="ä½ æ˜¯ä¸€ä¸ªæ„å›¾åˆ†ç±»å™¨ã€‚"
        )
        if "OPTIMIZE" in intent.upper():
            return "node_optimizer"
        else:
            return "node_chat"

    def optimizer_node(self, state: AgentState):
        """
        ã€å·¥å…·èŠ‚ç‚¹ã€‘è°ƒç”¨ ELE å¼•æ“æ‰§è¡Œä¼˜åŒ–ä»»åŠ¡
        """
        logger.info(" Agent is using Tool: Optimization Engine...")

        # 1. åˆå§‹åŒ–ä¼˜åŒ–å¼•æ“
        task_config = {"problem": {"problem_name": "User_Task"}, "max_fe": 10}
        ele = ELE_Service(task_config, llm_client=llm_service)

        # 2. æ‰§è¡Œä»»åŠ¡
        result = ele.run(query=state.query)

        # 3. æ›´æ–°çŠ¶æ€
        if result['status'] == 'success':
            #å±•ç¤ºä»£ç å’Œè¿è¡Œç»“æœ
            code_block = f"###  ç”Ÿæˆçš„ä»£ç \n```python\n{result.get('generated_code', '# No code')}\n```"
            output_block = f"###  è¿è¡Œç»“æœ\n{result['output']}"
            state.final_answer = f"{code_block}\n\n{output_block}"
        else:
            state.final_answer = f"æ‰§è¡Œå‡ºé”™: {result.get('error')}"

        return state

    def chat_node(self, state: AgentState):
        logger.info("ğŸ’¬ Tool: RAG Chat...")
        # ç®€å• RAGï¼šå…ˆä¸å¸¦ History æ£€ç´¢ï¼Œä½†å¸¦ History ç”Ÿæˆ
        search_res = rag_service.search(state.query)
        docs = search_res["results"]

        context_str = "\n".join(docs)
        sys_prompt = f"ä½ æ˜¯ä¸€ä¸ªçŸ¥è¯†åŠ©æ‰‹ã€‚ç»“åˆä¸Šä¸‹æ–‡å›ç­”ã€‚\nçŸ¥è¯†åº“ä¸Šä¸‹æ–‡:\n{context_str}"

        #  è¿™é‡ŒæŠŠ history ä¼ è¿›å»ï¼
        answer = llm_service.chat(prompt=state.query, system_prompt=sys_prompt, history=state.history)
        state.final_answer = answer
        return state

    def run(self, query: str, history: List[Dict] = []):
        state = AgentState(query, history)
        next_step = self.router_node(state)

        if next_step == "node_optimizer":
            self.optimizer_node(state)
        elif next_step == "node_chat":
            self.chat_node(state)

        return state.final_answer


agent_workflow = MeLA_Workflow()